{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big picture idea here is that I want to build a machine learning model that can predict when a county will have a high (>75th percentile) rate of COVID fatalities.  I have a wide range of data from countyhealthrankings.org (from 2019), the Social Vulnerability Index (2018) that I will use to predict.\n",
    "\n",
    "Then I will pull out the most important factors of that model. We have a lot of data that is moderately correlated with COVID fatality rates and often highly correlated with each other. So the machine learning model will help tease out what is really important within the raw data, in a way that minimizes my own biases.\n",
    "\n",
    "First, a bunch of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from COVID_data import prepare_model_data\n",
    "\n",
    "from sklearn.linear_model import Lasso, LogisticRegressionCV, LassoLarsCV, ElasticNetCV\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pprint\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "class config:\n",
    "    USE_CACHE = True\n",
    "    CACHE_DIR = \"/Users/caseydurfee/msds/data_mining_final_project/cache\"\n",
    "\n",
    "from COVID_data import all_data\n",
    "data = all_data.get_all_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at correlations in year 1 of the pandemic versus year 2 and see if there were changes.  Note that we are looking at all factors, including ones with large rates of missing data, which will artificially inflate those correlation scores. Some of these factors won't be used by the model, because I am throwing out any fields where more than 5% of counties have missing data.\n",
    "\n",
    "Here are the top 10 factors for each year, filtering out correlations with other death rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate_corr = data.corr()['DEATH_RATE_FIRST_YEAR']\n",
    "\n",
    "# omicron, alpha, delta, etc. death rates are not interesting here\n",
    "death_cols = list(data.filter(regex = 'DEATH'))\n",
    "\n",
    "y1_corr = death_rate_corr.reindex(death_rate_corr.abs().sort_values(ascending=False).index) \\\n",
    "    .drop(death_cols)\n",
    "\n",
    "print(y1_corr[-10:].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate_corr = data.corr()['DEATH_RATE_SECOND_YEAR']\n",
    "\n",
    "death_cols = list(data.filter(regex = 'DEATH'))\n",
    "\n",
    "y2_corr = death_rate_corr.reindex(death_rate_corr.abs().sort_values(ascending=False).index) \\\n",
    "    .drop(death_cols)\n",
    "\n",
    "print(y2_corr[-10:].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the top 10 correlations from year 1 and year 2 and see how they've changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_in_either = y1_corr[-10:].index.union(y2_corr[-10:].index)\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = ['Name', 'Year 1 r^2', 'Year 2 r^2']\n",
    "\n",
    "rows = []\n",
    "for c in cols_in_either:\n",
    "    row = [c, round(y1_corr[c], 3), round(y2_corr[c], 3)]\n",
    "    # pt.add_row(row)\n",
    "    rows.append(row)\n",
    "\n",
    "sorted_rows = sorted(rows, key=lambda x: abs(x[1]) + abs(x[2]), reverse=True)\n",
    "\n",
    "for x in sorted_rows:\n",
    "    pt.add_row(x)\n",
    "\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note here:\n",
    "* there are some metrics that are extremely similar (Years of Potential Life Lost Rate and Age-Adjusted Mortality are basically inverses of Life Expectancy). That's to be expected since they're generated by different teams, and we're going to let the model decide which one is the best for predicting high COVID fatality rates.\n",
    "\n",
    "* vaccination rates don't correlate strongly with year one fatality rate, which makes sense, given time only flows in one direction. They do show up as a major factor in year two, as expected.\n",
    "\n",
    "* The correlations in year 2 are all much stronger than year 1. This implies year 2 death rates were more predictable based on data we had before the pandemic (and hence the deaths were more preventable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the top factors correlate with each other. Are they all just saying the same thing? For each factor, we will print out the max correlation with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cols = list(data.filter(regex = 'DEATH'))\n",
    "\n",
    "top_factors = y2_corr[-20:].index\n",
    "\n",
    "corrs_with_eachother = data.corr().loc[top_factors, top_factors]\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = ['Column', 'Highest Correlated With', 'r^2']\n",
    "\n",
    "rows = []\n",
    "for col in corrs_with_eachother.columns:\n",
    "    other_cols = corrs_with_eachother[col].drop(col)\n",
    "    rows.append([col, other_cols.idxmax(), round(max(other_cols), 3)])\n",
    "\n",
    "\n",
    "sorted_rows = sorted(rows, key=lambda x: (x[1], 1-x[2]))\n",
    "\n",
    "for row in sorted_rows:\n",
    "    pt.add_row(row)\n",
    "\n",
    "print(pt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there's definitely some redundancy. But SVI's Per Capita estimate and Wikipedia's are less correlated than partial COVID vaccination coverage rate and complete coverage rate.\n",
    "\n",
    "REPUB_PARTISAN is the only one that isn't strongly correlated with anything else. It's also the only one, besides \"% Some College\", that isn't a measure of health, wealth, or vaccination levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to test a wide range of models and we'll go with whatever performs best.  Using ROC AUC as the scoring metric since we have unbalanced classes.\n",
    "\n",
    "We will drop all metrics that are missing more than 5% of their values. There are about 30 metrics that we don't have good coverage for. If we limit to counties over 50,000 people, we can an additional 10 or so metrics, and possibly lose some noise introduced by imputation done by the sources of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2718\n",
    "ITERS = 20000\n",
    "\n",
    "test_models = [ \n",
    "    RandomForestClassifier(random_state=SEED),\n",
    "    SVC(random_state=SEED),\n",
    "    LogisticRegressionCV(random_state=SEED),\n",
    "    RidgeClassifierCV(),\n",
    "    AdaBoostClassifier(random_state=SEED),\n",
    "    BaggingClassifier(random_state=SEED),\n",
    "    GradientBoostingClassifier(random_state=SEED),\n",
    "    LinearSVC(random_state=SEED),\n",
    "    LassoLarsCV(normalize=False),\n",
    "    ElasticNetCV(random_state=SEED)\n",
    "]\n",
    "roc_auc_scorer = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on year 1 and year 2 data combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taken from https://stackoverflow.com/questions/53784971/how-to-disable-convergencewarning-using-sklearn\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_combined():\n",
    "    df, X, y = prepare_model_data.get_train_data(data, year=False)\n",
    "\n",
    "    roc_scores = {}\n",
    "    max_roc = 0\n",
    "    for model in test_models:\n",
    "        model_name = str(model.__class__)\n",
    "\n",
    "        mean_score = cross_val_score(model, X, y, scoring=roc_auc_scorer).mean()\n",
    "\n",
    "        if model_name not in roc_scores:\n",
    "            roc_scores[model_name] = 0.0\n",
    "        roc_scores[model_name] += mean_score\n",
    "        if mean_score > max_roc:\n",
    "            best_model = model\n",
    "            max_roc = mean_score\n",
    "    return roc_scores\n",
    "\n",
    "roc_scores = train_combined()\n",
    "combo_roc = pd.Series(roc_scores)\n",
    "print(\">>>>Combined year 1 and year 2\")\n",
    "print(combo_roc.sort_values())\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def fit_yearly_models(iters = 1):\n",
    "    for year in [1,2]:\n",
    "        df, X, y = prepare_model_data.make_train_test(data, year=year, min_pop=50000, split=False)\n",
    "\n",
    "        roc_scores = {}\n",
    "        max_roc = 0.0\n",
    "        best_model = None\n",
    "        for i in range(iters):\n",
    "            for model in test_models:\n",
    "                model_name = repr(model.__class__)\n",
    "                \n",
    "                mean_score = cross_val_score(model, X, y, scoring=roc_auc_scorer).mean()\n",
    "\n",
    "                if model_name not in roc_scores:\n",
    "                    roc_scores[model_name] = 0.0\n",
    "                roc_scores[model_name] += mean_score\n",
    "                if mean_score > max_roc:\n",
    "                    best_model = model\n",
    "                    max_roc = mean_score\n",
    "\n",
    "        sz = pd.Series(roc_scores)\n",
    "        print(f\">>>> mean scores for year {year}\")\n",
    "        print(sz / iters)\n",
    "\n",
    "fit_yearly_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit on just the second year was much better across the board than the first year, or both years combined. To me, that implies that 2nd year deaths are more predictable than first year desaths.\n",
    "\n",
    "Looks like ElasticNetCV and LassoLarsCV are our big winners. They both apply regularization, which punishes models for being too complex, leading to them only using a subset of the factors we have. This is perfect for our purposes, since we're trying to pull out the top factors that matter the most.\n",
    "\n",
    "Because there's not a huge difference between them, I selected LassoLarsCV for the final models because it has less trouble converging on a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's use permutation importance to figure out what really matters to these models that we've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "df, X, y = prepare_model_data.get_train_data(data, year=1)\n",
    "\n",
    "y1_model = LassoLarsCV(normalize=False).fit(X, y)\n",
    "\n",
    "result = permutation_importance(y1_model, X, y, n_repeats=100)\n",
    "\n",
    "y1_importance = pd.Series(result.importances_mean, index=df.columns)\n",
    "\n",
    "disp = y1_importance.reindex(y1_importance.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"Year one\")\n",
    "print(disp[disp > 0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"% Vaccinated (CHR)\" measure is actually the standard childhood vaccines, not the COVID vaccine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X, y = prepare_model_data.get_train_data(data, year=2)\n",
    "\n",
    "y2_model = LassoLarsCV(normalize=False).fit(X, y)\n",
    "\n",
    "result = permutation_importance(y2_model, X, y, n_repeats=100)\n",
    "\n",
    "perm_importances = pd.Series(result.importances_mean, index=df.columns)\n",
    "\n",
    "y2_importance = perm_importances.reindex(perm_importances.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"Year two\")\n",
    "print(y2_importance[y2_importance > 0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These importances don't tell us the direction of the correlation (whether they increase or decrease the likelihood of a county having high COVID rates.) We can unite this data with the correlation data to show all factors that mattered during the pandemic. Let's see which factors showed up in one of the models and had a big change in correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = y1_importance.rename('Y1_IMPORTANCE').to_frame()\\\n",
    "    .join(y1_corr.rename(\"Y1_CORR\"))\\\n",
    "    .join(y2_importance.rename('Y2_IMPORTANCE'))\\\n",
    "    .join(y2_corr.rename(\"Y2_CORR\"))\n",
    "\n",
    "summary['CORR_DIFF'] = summary['Y2_CORR'] - summary['Y1_CORR']\n",
    "\n",
    "#summary[(summary.Y1_IMPORTANCE > 0) & (summary.Y2_IMPORTANCE > 0)].sort_values(by='Y2_IMPORTANCE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[(summary.Y1_IMPORTANCE > 0) | (summary.Y2_IMPORTANCE > 0)].sort_values(by='CORR_DIFF', key=lambda x: abs(x), ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if ElasticNetCV would give us different factors for year two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X, y = prepare_model_data.get_train_data(data, year=2)\n",
    "\n",
    "enet_model = ElasticNetCV().fit(X, y)\n",
    "\n",
    "result = permutation_importance(enet_model, X, y, n_repeats=100)\n",
    "\n",
    "perm_importances = pd.Series(result.importances_mean, index=df.columns)\n",
    "\n",
    "y2_enet = perm_importances.reindex(perm_importances.abs().sort_values().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_vs_lars = y2_enet.rename('Y2_ENET').to_frame()\\\n",
    "    .join(y2_importance.rename('Y2_LARS'))\n",
    "\n",
    "enet_vs_lars['ENET_RANK'] = enet_vs_lars['Y2_ENET'].rank(ascending=False)\n",
    "enet_vs_lars['LARS_RANK'] = enet_vs_lars['Y2_LARS'].rank(ascending=False)\n",
    "\n",
    "enet_vs_lars[\"RANK_CHANGE\"] = abs(enet_vs_lars['ENET_RANK'] - enet_vs_lars['LARS_RANK'])\n",
    "\n",
    "\n",
    "enet_vs_lars[((enet_vs_lars.Y2_ENET > 0) | (enet_vs_lars.Y2_LARS > 0)) & (enet_vs_lars.ENET_RANK < 21)].sort_values(by='ENET_RANK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the rankings are remarkably consistent between the two models. The order is slightly different, but the top 20 factors are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a couple of the less accurate models and see what factors they deem important. \n",
    "\n",
    "First off, let's try LogisticRegressionCV. Because it doesn't have a regularization penalty, it will use all 80 factors in the model, so we will only display the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv_model = LogisticRegressionCV(max_iter=20000).fit(X, y)\n",
    "\n",
    "result = permutation_importance(lrcv_model, X, y, \n",
    "            n_repeats=100)\n",
    "\n",
    "perm_importances = pd.Series(result.importances_mean, index=df.columns)\n",
    "\n",
    "y2_lrcv = perm_importances.reindex(perm_importances.abs().sort_values().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y2_lrcv[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that LARS and ENET had the same top 20 factors. What about LRCV? How much overlap is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_vs_lars[-20:].index.intersection(y2_lrcv[-20:].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_vs_lars[-10:].index.intersection(y2_lrcv[-10:].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC(max_iter=50000).fit(X,y)\n",
    "\n",
    "result = permutation_importance(svc_model, X, y, \n",
    "            n_repeats=100)\n",
    "\n",
    "perm_importances = pd.Series(result.importances_mean, index=df.columns)\n",
    "\n",
    "y2_svc = perm_importances.reindex(perm_importances.abs().sort_values().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_vs_lars[-20:].index.intersection(y2_svc[-20:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_vs_lars[-10:].index.intersection(y2_svc[-10:].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four models identified `2016 Repub Vote Share` as the most important factor and `Physically Unhealthy Days (CHR)` as also being important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been looking at all counties. However, many of the metrics we have are imputed by the sources we got them from (SVI, County Health Rankings, CDC, etc.) Those data sources provide confidence intervals on their estimations but we're not using those.\n",
    "\n",
    "So it makes sense to look at just big US counties (over 50,000 population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X, y = prepare_model_data.make_train_test(data, year=2, min_pop=50000, split=False)\n",
    "\n",
    "y2_bigcounty_model = LassoLarsCV(normalize=False).fit(X, y)\n",
    "\n",
    "result = permutation_importance(y2_bigcounty_model, X, y, n_repeats=100)\n",
    "\n",
    "perm_importances = pd.Series(result.importances_mean, index=df.columns)\n",
    "\n",
    "y2_bigcounty_importance = perm_importances.reindex(perm_importances.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"Year two - Big Counties Only\")\n",
    "print(y2_bigcounty_importance[y2_bigcounty_importance > 0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again REPUB_PARTISAN is the strongest factor used by the model to predict high COVID fatality rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e5e67dba9ec50688b51d210d69127116c7da1f67ec0df7da4b6c1a14dc73fba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py3-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
